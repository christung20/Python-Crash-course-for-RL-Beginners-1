{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gymnasium - An API standard for reinforcement learning with a diverse collection of reference environments\n",
        "\n",
        "Documents: https://gymnasium.farama.org/introduction/train_agent/\n",
        "\n",
        "Gymnasium is a project that provides an API (application programming interface) for all single agent reinforcement learning environments, with implementations of common environments: cartpole, pendulum, mountain-car, mujoco, atari, and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Stable Baselines3 - Training, Saving and Loading\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a training framework for Reinforcement Learning (RL), using Stable Baselines3.\n",
        "\n",
        "It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.\n",
        "\n",
        "Documentation is available online: [https://stable-baselines3.readthedocs.io/](https://stable-baselines3.readthedocs.io/)\n",
        "\n",
        "Examples with Collab Code: [https://stable-baselines3.readthedocs.io/en/master/guide/examples.html](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Open a Terminal and install the following packages:\n",
        "\n",
        "sudo apt-get install build-essential python-dev-is-python3 swig python3-pygame git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. autoformatting and install box2d-py and stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gGbS4lII8i_"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWskDE2c9WoN",
        "outputId": "bdd6e935-52e2-4fa3-f64c-cd78d6447468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: box2d-py in ./.venv/lib/python3.12/site-packages (2.3.8)\n",
            "Requirement already satisfied: stable-baselines3>=2.0.0a4 in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.7.0a0)\n",
            "Requirement already satisfied: gymnasium[other] in ./.venv/lib/python3.12/site-packages (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in ./.venv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.3.1)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in ./.venv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.7.1)\n",
            "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (from stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in ./.venv/lib/python3.12/site-packages (from gymnasium[other]) (4.14.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in ./.venv/lib/python3.12/site-packages (from gymnasium[other]) (0.0.4)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.18.0)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.3.1)\n",
            "Collecting moviepy>=1.0.0 (from gymnasium[other])\n",
            "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: opencv-python>=3.0 in ./.venv/lib/python3.12/site-packages (from gymnasium[other]) (4.11.0.86)\n",
            "Collecting seaborn>=0.13 (from gymnasium[other])\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2.9.0.post0)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in ./.venv/lib/python3.12/site-packages (from moviepy>=1.0.0->gymnasium[other]) (5.2.1)\n",
            "Collecting imageio<3.0,>=2.5 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting imageio_ffmpeg>=0.2.0 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting proglog<=1.0.0 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting python-dotenv>=0.10 (from moviepy>=1.0.0->gymnasium[other])\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from proglog<=1.0.0->moviepy>=1.0.0->gymnasium[other]) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (2025.2)\n",
            "Requirement already satisfied: pygame in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (2.19.0)\n",
            "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (7.0.0)\n",
            "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (14.0.0)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in ./.venv/lib/python3.12/site-packages (from stable-baselines3[extra]>=2.0.0a4) (0.11.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3>=2.0.0a4->stable-baselines3[extra]>=2.0.0a4) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (6.31.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.12/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a4) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->stable-baselines3[extra]>=2.0.0a4) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a4) (0.1.2)\n",
            "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
            "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Installing collected packages: python-dotenv, proglog, imageio_ffmpeg, imageio, moviepy, seaborn\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [seaborn]m5/6\u001b[0m [seaborn]ffmpeg]\n",
            "\u001b[1A\u001b[2KSuccessfully installed imageio-2.37.0 imageio_ffmpeg-0.6.0 moviepy-2.2.1 proglog-0.1.12 python-dotenv-1.1.1 seaborn-0.13.2\n"
          ]
        }
      ],
      "source": [
        "# Use pip to install box2d-py and stable-baselines3[extra] which required >= 2.0.0a4\n",
        "# and gymnasium[other] which includes pymovie\n",
        "\n",
        "!pip install box2d-py\n",
        "!pip install \"stable-baselines3[extra]>=2.0.0a4\" \"gymnasium[other]\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Import policy, RL agent and create directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directories for models, videos and tb_logs\n",
        "\n",
        "import os\n",
        "\n",
        "model_dir = \"models/dqn_lunar\"\n",
        "video_final_dir = \"videos/final\"\n",
        "video_progress_dir = \"videos/progress\"\n",
        "log_dir = \"tb_logs\"\n",
        "\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "os.makedirs(video_final_dir, exist_ok=True)\n",
        "os.makedirs(video_progress_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RapkYvTXL7Cd"
      },
      "source": [
        "## Create the Gym env and instantiate the agent\n",
        "\n",
        "For this example, we will use Lunar Lander environment.\n",
        "\n",
        "\"Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Four discrete actions available: do nothing, fire left orientation engine, fire main engine, fire right orientation engine. \"\n",
        "\n",
        "Lunar Lander environment: [https://gymnasium.farama.org/environments/box2d/lunar_lander/](https://gymnasium.farama.org/environments/box2d/lunar_lander/)\n",
        "\n",
        "![Lunar Lander](https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif)\n",
        "\n",
        "\n",
        "We chose the MlpPolicy because input of Lunar Lander is a feature vector, not images.\n",
        "\n",
        "The type of action to use (discrete/continuous) will be automatically deduced from the environment action space\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWGZp3i9wyf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/christung/Python-Crash-course-for-RL-Beginners/.venv/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/christung/Python-Crash-course-for-RL-Beginners/videos/final folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# Seperate env for evaluation which have a RecordVideo wrappers\n",
        "eval_env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
        "eval_env = gym.wrappers.RecordVideo(eval_env, video_folder=video_progress_dir, episode_trigger=lambda ep: ep==0)\n",
        "\n",
        "# Create a evaluation model\n",
        "eval_model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    eval_env,\n",
        "    verbose=1,\n",
        "    exploration_final_eps=0.1,\n",
        "    target_update_interval=250,\n",
        "    tensorboard_log=log_dir,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4efFdrQ7MBvl"
      },
      "source": [
        "We load a helper function to evaluate the agent:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeaVBGuJwK97"
      },
      "outputs": [],
      "source": [
        "# import a helper function: evaluate_policy to evaluate the policy\n",
        "\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjEVOIY8NVeK"
      },
      "source": [
        "Let's evaluate the un-trained agent, this should be a random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDHLMA6NFk95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/christung/Python-Crash-course-for-RL-Beginners/.venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward=-105.92 +/- 0.0\n"
          ]
        }
      ],
      "source": [
        "# Separate env for evaluation, using render_mode=\"rgb_array\"\n",
        "\n",
        "# Before training, how agent is performed and its mean of rewards and std of rewards\n",
        "\n",
        "# print out its mean of rewards and std of rewards and video saved in video_dir\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(\n",
        "    eval_model,\n",
        "    eval_env,\n",
        "    n_eval_episodes=1,\n",
        "    deterministic=True,\n",
        "    render=False,\n",
        ")\n",
        "\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train the agent and save it\n",
        "\n",
        "Warning: this may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4cfSXIB-pTF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Logging to tb_logs/dqn_lunar_2\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | -102     |\n",
            "|    exploration_rate | 0.962    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 19       |\n",
            "|    time_elapsed     | 21       |\n",
            "|    total_timesteps  | 419      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.09     |\n",
            "|    n_updates        | 79       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.1     |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.93     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 31       |\n",
            "|    time_elapsed     | 24       |\n",
            "|    total_timesteps  | 777      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.761    |\n",
            "|    n_updates        | 169      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.5     |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.898    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 43       |\n",
            "|    time_elapsed     | 25       |\n",
            "|    total_timesteps  | 1134     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.89     |\n",
            "|    n_updates        | 258      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.6     |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.87     |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 52       |\n",
            "|    time_elapsed     | 27       |\n",
            "|    total_timesteps  | 1450     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.99     |\n",
            "|    n_updates        | 337      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.7     |\n",
            "|    ep_rew_mean      | -161     |\n",
            "|    exploration_rate | 0.837    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 62       |\n",
            "|    time_elapsed     | 28       |\n",
            "|    total_timesteps  | 1814     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.13     |\n",
            "|    n_updates        | 428      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.1     |\n",
            "|    ep_rew_mean      | -169     |\n",
            "|    exploration_rate | 0.805    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 72       |\n",
            "|    time_elapsed     | 29       |\n",
            "|    total_timesteps  | 2163     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.651    |\n",
            "|    n_updates        | 515      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.9     |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.761    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 31       |\n",
            "|    total_timesteps  | 2656     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.92     |\n",
            "|    n_updates        | 638      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.6     |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.719    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 96       |\n",
            "|    time_elapsed     | 32       |\n",
            "|    total_timesteps  | 3122     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.838    |\n",
            "|    n_updates        | 755      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97       |\n",
            "|    ep_rew_mean      | -195     |\n",
            "|    exploration_rate | 0.686    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 104      |\n",
            "|    time_elapsed     | 33       |\n",
            "|    total_timesteps  | 3491     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.44     |\n",
            "|    n_updates        | 847      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 100      |\n",
            "|    ep_rew_mean      | -203     |\n",
            "|    exploration_rate | 0.64     |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 114      |\n",
            "|    time_elapsed     | 35       |\n",
            "|    total_timesteps  | 4000     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.61     |\n",
            "|    n_updates        | 974      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 106      |\n",
            "|    ep_rew_mean      | -205     |\n",
            "|    exploration_rate | 0.58     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 128      |\n",
            "|    time_elapsed     | 36       |\n",
            "|    total_timesteps  | 4665     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.639    |\n",
            "|    n_updates        | 1141     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 109      |\n",
            "|    ep_rew_mean      | -197     |\n",
            "|    exploration_rate | 0.529    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 138      |\n",
            "|    time_elapsed     | 37       |\n",
            "|    total_timesteps  | 5232     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.06     |\n",
            "|    n_updates        | 1282     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | -198     |\n",
            "|    exploration_rate | 0.451    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 70       |\n",
            "|    total_timesteps  | 6105     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.823    |\n",
            "|    n_updates        | 1501     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 120      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.396    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 93       |\n",
            "|    time_elapsed     | 71       |\n",
            "|    total_timesteps  | 6711     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.81     |\n",
            "|    n_updates        | 1652     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 134      |\n",
            "|    ep_rew_mean      | -194     |\n",
            "|    exploration_rate | 0.275    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 105      |\n",
            "|    time_elapsed     | 76       |\n",
            "|    total_timesteps  | 8056     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.04     |\n",
            "|    n_updates        | 1988     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 149      |\n",
            "|    ep_rew_mean      | -191     |\n",
            "|    exploration_rate | 0.143    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 118      |\n",
            "|    time_elapsed     | 80       |\n",
            "|    total_timesteps  | 9518     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.47     |\n",
            "|    n_updates        | 2354     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 167      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 128      |\n",
            "|    time_elapsed     | 88       |\n",
            "|    total_timesteps  | 11380    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.06     |\n",
            "|    n_updates        | 2819     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 175      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 137      |\n",
            "|    time_elapsed     | 91       |\n",
            "|    total_timesteps  | 12571    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.2      |\n",
            "|    n_updates        | 3117     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 182      |\n",
            "|    ep_rew_mean      | -185     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 144      |\n",
            "|    time_elapsed     | 95       |\n",
            "|    total_timesteps  | 13818    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.16     |\n",
            "|    n_updates        | 3429     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -189     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 148      |\n",
            "|    time_elapsed     | 108      |\n",
            "|    total_timesteps  | 16064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.943    |\n",
            "|    n_updates        | 3990     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -201     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 150      |\n",
            "|    time_elapsed     | 111      |\n",
            "|    total_timesteps  | 16774    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 4168     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | -214     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 155      |\n",
            "|    time_elapsed     | 114      |\n",
            "|    total_timesteps  | 17830    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 7.38     |\n",
            "|    n_updates        | 4432     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 158      |\n",
            "|    time_elapsed     | 115      |\n",
            "|    total_timesteps  | 18376    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.22     |\n",
            "|    n_updates        | 4568     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -232     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 161      |\n",
            "|    time_elapsed     | 118      |\n",
            "|    total_timesteps  | 19130    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.21     |\n",
            "|    n_updates        | 4757     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 198      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 165      |\n",
            "|    time_elapsed     | 119      |\n",
            "|    total_timesteps  | 19794    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.45     |\n",
            "|    n_updates        | 4923     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -247     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 161      |\n",
            "|    time_elapsed     | 127      |\n",
            "|    total_timesteps  | 20584    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.36     |\n",
            "|    n_updates        | 5120     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | -252     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 162      |\n",
            "|    time_elapsed     | 129      |\n",
            "|    total_timesteps  | 21102    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.54     |\n",
            "|    n_updates        | 5250     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -257     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 163      |\n",
            "|    time_elapsed     | 132      |\n",
            "|    total_timesteps  | 21659    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.18     |\n",
            "|    n_updates        | 5389     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | -260     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 161      |\n",
            "|    time_elapsed     | 142      |\n",
            "|    total_timesteps  | 22928    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.79     |\n",
            "|    n_updates        | 5706     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 243      |\n",
            "|    ep_rew_mean      | -258     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 164      |\n",
            "|    time_elapsed     | 158      |\n",
            "|    total_timesteps  | 26081    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.949    |\n",
            "|    n_updates        | 6495     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 271      |\n",
            "|    ep_rew_mean      | -255     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 168      |\n",
            "|    time_elapsed     | 173      |\n",
            "|    total_timesteps  | 29256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.13     |\n",
            "|    n_updates        | 7288     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 306      |\n",
            "|    ep_rew_mean      | -252     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 171      |\n",
            "|    time_elapsed     | 193      |\n",
            "|    total_timesteps  | 33256    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.06     |\n",
            "|    n_updates        | 8288     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 337      |\n",
            "|    ep_rew_mean      | -246     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 173      |\n",
            "|    time_elapsed     | 211      |\n",
            "|    total_timesteps  | 36810    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 3.64     |\n",
            "|    n_updates        | 9177     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 358      |\n",
            "|    ep_rew_mean      | -240     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 178      |\n",
            "|    time_elapsed     | 219      |\n",
            "|    total_timesteps  | 39305    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.42     |\n",
            "|    n_updates        | 9801     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 366      |\n",
            "|    ep_rew_mean      | -236     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 182      |\n",
            "|    time_elapsed     | 222      |\n",
            "|    total_timesteps  | 40614    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.842    |\n",
            "|    n_updates        | 10128    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 383      |\n",
            "|    ep_rew_mean      | -228     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 182      |\n",
            "|    time_elapsed     | 234      |\n",
            "|    total_timesteps  | 42934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 10708    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 388      |\n",
            "|    ep_rew_mean      | -229     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 184      |\n",
            "|    time_elapsed     | 238      |\n",
            "|    total_timesteps  | 43982    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.41     |\n",
            "|    n_updates        | 10970    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 388      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 370      |\n",
            "|    total_timesteps  | 44939    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.02     |\n",
            "|    n_updates        | 11209    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 395      |\n",
            "|    ep_rew_mean      | -226     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 381      |\n",
            "|    total_timesteps  | 46185    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.834    |\n",
            "|    n_updates        | 11521    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 388      |\n",
            "|    ep_rew_mean      | -223     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 122      |\n",
            "|    time_elapsed     | 383      |\n",
            "|    total_timesteps  | 46864    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.66     |\n",
            "|    n_updates        | 11690    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 381      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 386      |\n",
            "|    total_timesteps  | 47648    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.874    |\n",
            "|    n_updates        | 11886    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 369      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 124      |\n",
            "|    time_elapsed     | 388      |\n",
            "|    total_timesteps  | 48309    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.979    |\n",
            "|    n_updates        | 12052    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 362      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 125      |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 48819    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.949    |\n",
            "|    n_updates        | 12179    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 360      |\n",
            "|    ep_rew_mean      | -222     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 126      |\n",
            "|    time_elapsed     | 392      |\n",
            "|    total_timesteps  | 49768    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.1      |\n",
            "|    n_updates        | 12416    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 351      |\n",
            "|    ep_rew_mean      | -213     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 128      |\n",
            "|    time_elapsed     | 398      |\n",
            "|    total_timesteps  | 51176    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.96     |\n",
            "|    n_updates        | 12768    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 350      |\n",
            "|    ep_rew_mean      | -202     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 129      |\n",
            "|    time_elapsed     | 399      |\n",
            "|    total_timesteps  | 51755    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.874    |\n",
            "|    n_updates        | 12913    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 348      |\n",
            "|    ep_rew_mean      | -188     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 130      |\n",
            "|    time_elapsed     | 402      |\n",
            "|    total_timesteps  | 52666    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.899    |\n",
            "|    n_updates        | 13141    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 350      |\n",
            "|    ep_rew_mean      | -178     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 131      |\n",
            "|    time_elapsed     | 405      |\n",
            "|    total_timesteps  | 53410    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.81     |\n",
            "|    n_updates        | 13327    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -167     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 132      |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 54298    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.996    |\n",
            "|    n_updates        | 13549    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 352      |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 132      |\n",
            "|    time_elapsed     | 414      |\n",
            "|    total_timesteps  | 54992    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.28     |\n",
            "|    n_updates        | 13722    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 350      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 113      |\n",
            "|    time_elapsed     | 488      |\n",
            "|    total_timesteps  | 55634    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.66     |\n",
            "|    n_updates        | 13883    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 355      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 114      |\n",
            "|    time_elapsed     | 494      |\n",
            "|    total_timesteps  | 56566    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.9      |\n",
            "|    n_updates        | 14116    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 354      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 115      |\n",
            "|    time_elapsed     | 495      |\n",
            "|    total_timesteps  | 57067    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.765    |\n",
            "|    n_updates        | 14241    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 348      |\n",
            "|    ep_rew_mean      | -140     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 116      |\n",
            "|    time_elapsed     | 497      |\n",
            "|    total_timesteps  | 57741    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.38     |\n",
            "|    n_updates        | 14410    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 323      |\n",
            "|    ep_rew_mean      | -141     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 116      |\n",
            "|    time_elapsed     | 499      |\n",
            "|    total_timesteps  | 58346    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.743    |\n",
            "|    n_updates        | 14561    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 297      |\n",
            "|    ep_rew_mean      | -142     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 117      |\n",
            "|    time_elapsed     | 501      |\n",
            "|    total_timesteps  | 58976    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 14718    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 268      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 118      |\n",
            "|    time_elapsed     | 507      |\n",
            "|    total_timesteps  | 60034    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.02     |\n",
            "|    n_updates        | 14983    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | -146     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 119      |\n",
            "|    time_elapsed     | 509      |\n",
            "|    total_timesteps  | 60731    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.651    |\n",
            "|    n_updates        | 15157    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 221      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 510      |\n",
            "|    total_timesteps  | 61398    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.42     |\n",
            "|    n_updates        | 15324    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 214      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 512      |\n",
            "|    total_timesteps  | 62044    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.04     |\n",
            "|    n_updates        | 15485    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 514      |\n",
            "|    total_timesteps  | 62640    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.597    |\n",
            "|    n_updates        | 15634    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 515      |\n",
            "|    total_timesteps  | 63462    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.5      |\n",
            "|    n_updates        | 15840    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | -147     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 118      |\n",
            "|    time_elapsed     | 539      |\n",
            "|    total_timesteps  | 64220    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.14     |\n",
            "|    n_updates        | 16029    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 119      |\n",
            "|    time_elapsed     | 544      |\n",
            "|    total_timesteps  | 65159    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.95     |\n",
            "|    n_updates        | 16264    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 119      |\n",
            "|    time_elapsed     | 555      |\n",
            "|    total_timesteps  | 66384    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.749    |\n",
            "|    n_updates        | 16570    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 558      |\n",
            "|    total_timesteps  | 67191    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 16772    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | -151     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 562      |\n",
            "|    total_timesteps  | 67812    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.684    |\n",
            "|    n_updates        | 16927    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 566      |\n",
            "|    total_timesteps  | 68560    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.827    |\n",
            "|    n_updates        | 17114    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 569      |\n",
            "|    total_timesteps  | 69318    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.1      |\n",
            "|    n_updates        | 17304    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 577      |\n",
            "|    total_timesteps  | 70414    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.39     |\n",
            "|    n_updates        | 17578    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 197      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 580      |\n",
            "|    total_timesteps  | 71479    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.62     |\n",
            "|    n_updates        | 17844    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 582      |\n",
            "|    total_timesteps  | 72021    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 5.92     |\n",
            "|    n_updates        | 17980    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 124      |\n",
            "|    time_elapsed     | 584      |\n",
            "|    total_timesteps  | 72586    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.55     |\n",
            "|    n_updates        | 18121    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 189      |\n",
            "|    ep_rew_mean      | -150     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 125      |\n",
            "|    time_elapsed     | 585      |\n",
            "|    total_timesteps  | 73196    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.803    |\n",
            "|    n_updates        | 18273    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 125      |\n",
            "|    time_elapsed     | 587      |\n",
            "|    total_timesteps  | 73996    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.931    |\n",
            "|    n_updates        | 18473    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 118      |\n",
            "|    time_elapsed     | 631      |\n",
            "|    total_timesteps  | 75045    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.02     |\n",
            "|    n_updates        | 18736    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | -144     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 119      |\n",
            "|    time_elapsed     | 633      |\n",
            "|    total_timesteps  | 75628    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.66     |\n",
            "|    n_updates        | 18881    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 636      |\n",
            "|    total_timesteps  | 76479    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.36     |\n",
            "|    n_updates        | 19094    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | -142     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 120      |\n",
            "|    time_elapsed     | 638      |\n",
            "|    total_timesteps  | 77307    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.742    |\n",
            "|    n_updates        | 19301    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | -142     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 121      |\n",
            "|    time_elapsed     | 641      |\n",
            "|    total_timesteps  | 78215    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.706    |\n",
            "|    n_updates        | 19528    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -142     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 122      |\n",
            "|    time_elapsed     | 643      |\n",
            "|    total_timesteps  | 79043    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 4.73     |\n",
            "|    n_updates        | 19735    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -143     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 652      |\n",
            "|    total_timesteps  | 80239    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.15     |\n",
            "|    n_updates        | 20034    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -145     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 123      |\n",
            "|    time_elapsed     | 653      |\n",
            "|    total_timesteps  | 80771    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.51     |\n",
            "|    n_updates        | 20167    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 201      |\n",
            "|    ep_rew_mean      | -148     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 124      |\n",
            "|    time_elapsed     | 655      |\n",
            "|    total_timesteps  | 81530    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.46     |\n",
            "|    n_updates        | 20357    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | -152     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 125      |\n",
            "|    time_elapsed     | 658      |\n",
            "|    total_timesteps  | 82573    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.822    |\n",
            "|    n_updates        | 20618    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 126      |\n",
            "|    time_elapsed     | 660      |\n",
            "|    total_timesteps  | 83330    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.26     |\n",
            "|    n_updates        | 20807    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 127      |\n",
            "|    time_elapsed     | 662      |\n",
            "|    total_timesteps  | 84235    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 2.16     |\n",
            "|    n_updates        | 21033    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 124      |\n",
            "|    time_elapsed     | 682      |\n",
            "|    total_timesteps  | 84878    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.741    |\n",
            "|    n_updates        | 21194    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -153     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 124      |\n",
            "|    time_elapsed     | 684      |\n",
            "|    total_timesteps  | 85572    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.1      |\n",
            "|    n_updates        | 21367    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -157     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 126      |\n",
            "|    time_elapsed     | 688      |\n",
            "|    total_timesteps  | 86750    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 21662    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 202      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 126      |\n",
            "|    time_elapsed     | 689      |\n",
            "|    total_timesteps  | 87441    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.842    |\n",
            "|    n_updates        | 21835    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 127      |\n",
            "|    time_elapsed     | 692      |\n",
            "|    total_timesteps  | 88494    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.909    |\n",
            "|    n_updates        | 22098    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -154     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 128      |\n",
            "|    time_elapsed     | 694      |\n",
            "|    total_timesteps  | 89373    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 22318    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 208      |\n",
            "|    ep_rew_mean      | -155     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 129      |\n",
            "|    time_elapsed     | 696      |\n",
            "|    total_timesteps  | 90081    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.852    |\n",
            "|    n_updates        | 22495    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 130      |\n",
            "|    time_elapsed     | 698      |\n",
            "|    total_timesteps  | 90849    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.15     |\n",
            "|    n_updates        | 22687    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 131      |\n",
            "|    time_elapsed     | 700      |\n",
            "|    total_timesteps  | 91770    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.687    |\n",
            "|    n_updates        | 22917    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | -159     |\n",
            "|    exploration_rate | 0.1      |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 131      |\n",
            "|    time_elapsed     | 702      |\n",
            "|    total_timesteps  | 92657    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.01     |\n",
            "|    n_updates        | 23139    |\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Trigger video creation every 1000 episode\n",
        "def episode_trigger(ep):\n",
        "    return ep % 50 == 0\n",
        "\n",
        "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
        "env = gym.wrappers.RecordVideo(eval_env, video_folder=video_progress_dir, episode_trigger=episode_trigger)\n",
        "\n",
        "# Create a DQN model\n",
        "\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    exploration_final_eps=0.1,\n",
        "    target_update_interval=250,\n",
        "    tensorboard_log=log_dir,\n",
        ")\n",
        "\n",
        "# Save every 10000 steps\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_path=\"models/dqn_lunar\",\n",
        "    save_freq=10000,\n",
        "    name_prefix=\"dqn_lunar\",\n",
        ")\n",
        "# Start training the agent with timesteps of 100000, using checkpoint callback and setting tensorboard log name to \"dqn_lunar\"\n",
        "\n",
        "model.learn(total_timesteps=int(1e5), callback=checkpoint_callback, tb_log_name=log_dir)\n",
        "\n",
        "# Save the agent optionally\n",
        "model.save(\"dqn_lunar_final\")\n",
        "\n",
        "# delete trained model to demonstrate loading\n",
        "del model  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T31dZJYNrJwF"
      },
      "source": [
        "## Load the trained agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1ExgtyZrIA6"
      },
      "outputs": [],
      "source": [
        "# load a specific checkpoint file dqn_lunar_final.zip\n",
        "\n",
        "load_model = DQN.load(\"dqn_lunar_final\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create evaluation env and create a video using RecordVideo wrapper\n",
        "\n",
        "eval_env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
        "eval_env = gym.wrappers.RecordVideo(eval_env, video_folder=video_final_dir, episode_trigger=lambda ep: ep==0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygl_gVmV_QP7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/christung/Python-Crash-course-for-RL-Beginners/.venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward=90.46 +/- 0.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained agent\n",
        "mean_reward, std_reward = evaluate_policy(load_model, eval_env, n_eval_episodes=1, deterministic=True, render=False)\n",
        "\n",
        "# print out the mean of rewards and std of rewards after training\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# close the environment\n",
        "\n",
        "eval_env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ==============================================\n",
        "# Final Task: If time is allowed, increase the training frequency such that the mean_reward score can go up to 100+ mark. Can you tell how many times you need to train the model ?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
